{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###### Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime as dt\n",
    "import folium\n",
    "from folium import plugins\n",
    "import geopandas\n",
    "from calendar import monthrange\n",
    "\n",
    "spray_data = pd.read_csv(\n",
    "    'Files/spray.csv',  # шлях до файлу, який містить дані\n",
    "    sep=',',  # роздільник стовпців\n",
    "    header=0  # номер рядка, що містить заголовок (якщо заголовка немає, можна передати None)\n",
    ")\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    'Files/train.csv',  # шлях до файлу, який містить дані\n",
    "    sep=',',  # роздільник стовпців\n",
    "    \n",
    "    header=0  # номер рядка, що містить заголовок (якщо заголовка немає, можна передати None)\n",
    ")\n",
    "\n",
    "weather_data = pd.read_csv(\n",
    "    'Files/weather.csv',  # шлях до файлу, який містить дані\n",
    "    sep=',',  # роздільник стовпців\n",
    "    header=0  # номер рядка, що містить заголовок (якщо заголовка немає, можна передати None)\n",
    ")\n",
    "\n",
    "test_truncated_data = pd.read_excel(\n",
    "    'Files/test_truncated.xlsx',\n",
    "    sheet_name='test_truncated',  # прочитати всі листи\n",
    "    usecols=\"A:J\"\n",
    "    #nrows=5\n",
    ")\n",
    "#test_truncated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime(train_data):\n",
    "    train_data['day']=pd.to_datetime(train_data.Date).dt.day\n",
    "    train_data['weekday']=pd.to_datetime(train_data.Date).dt.weekday\n",
    "    train_data['month']=pd.to_datetime(train_data.Date).dt.month\n",
    "    train_data['year']=pd.to_datetime(train_data.Date).dt.year\n",
    "    return train_data\n",
    "\n",
    "def bar_chat(_data, grop_list_, agr_colum, agr_func):\n",
    "    grop_list=[grop_list_]\n",
    "    agg_func_math = {\n",
    "        agr_colum: [agr_func]\n",
    "    }\n",
    "    plot_mas = _data.groupby(grop_list, group_keys=True, dropna=True).agg(agg_func_math).to_dict()[(agr_colum, agr_func)] \n",
    "    fig = plt.figure()\n",
    "    plt.bar(plot_mas.keys(), plot_mas.values())\n",
    "    plt.title(f'{grop_list_} {agr_colum} {agr_func} chart')    \n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "#bar_chat(test_truncated_data, 'year', 'year', 'count')\n",
    "\n",
    "def group_data(_data, grop_list_, agr_colum, agr_func):\n",
    "    grop_list=[grop_list_]\n",
    "    agg_func_math = {\n",
    "        agr_colum: [agr_func]\n",
    "    }\n",
    "    dict_data=_data.groupby(grop_list, group_keys=True, dropna=True).agg(agg_func_math).to_dict()[(agr_colum, agr_func)]\n",
    "    df=pd.DataFrame(list(dict_data. items ()), columns = [grop_list_, agr_colum])\n",
    "    #df.set_index(df[grop_list], *, drop=True, append=False, inplace=False, verify_integrity=False)[source]\n",
    "    df.set_index(grop_list, inplace=True)\n",
    "    return df.copy()\n",
    "\n",
    "def concat_train_data(train_data):\n",
    "    Trap=group_data(train_data, 'Trap', 'Latitude', 'min')\n",
    "    Longitude=group_data(train_data, 'Trap', 'Longitude', 'min')\n",
    "    NumMosquitos=group_data(train_data, 'Trap', 'NumMosquitos', 'sum')\n",
    "    WnvPresent=group_data(train_data, 'Trap', 'WnvPresent', 'sum')\n",
    "    AddressAccuracy=group_data(train_data, 'Trap', 'AddressAccuracy', 'min')\n",
    "    RESTUANS=group_data(train_data, 'Trap', 'RESTUANS', 'sum')\n",
    "    PIPIENS=group_data(train_data, 'Trap', 'PIPIENS', 'sum')\n",
    "    Date_Min=group_data(train_data, 'Trap', 'Date', 'min')\n",
    "    #Date_Max=group_data(train_data, 'Trap', 'Date', 'max')\n",
    "    \n",
    "    frames = [Trap, Longitude, Date_Min, NumMosquitos, WnvPresent, AddressAccuracy, RESTUANS, PIPIENS]\n",
    "    result = pd.concat(frames, axis=1)\n",
    "    result.reset_index(inplace=True)\n",
    "    return result.copy()\n",
    "#train_data\n",
    "#df=concat_train_data(train_data[(train_data['year']==2013)])\n",
    "#df['test']='2021'\n",
    "#df\n",
    "#weather_data\n",
    "def make_category(X_Data, list_category):\n",
    "    for i in list_category:\n",
    "        X_Data['Cat_category']=X_Data[i].astype(\"category\")\n",
    "        clear_data(X_Data, [i], revers=False)\n",
    "        print(i)\n",
    "        X_Data.rename(\n",
    "            columns={'Cat_category': i,  # колонка \"SibSp\" буде перейменована на \"SiblingsSpouses\"\n",
    "                    }, inplace=True  # покажчик того, що зміни вносяться до існуючої таблиці\n",
    "        )\n",
    "    return X_Data\n",
    "\n",
    "def clear_data(test_data, drop_list, revers):\n",
    "    columns_df=[column for column in test_data]\n",
    "    #print(columns_df)\n",
    "    if revers==False:\n",
    "        for i in drop_list:\n",
    "            if i in columns_df:\n",
    "                test_data.drop(\n",
    "                    i,  # список колонок або рядків, які потрібно видалити\n",
    "                    axis=1,  # видалення рядків відбувається аналогічно, щоб видалити саме колонки, вибираємо відповідну вісь\n",
    "                    inplace=True  # видалення \"на місці\", без надання нової змінної\n",
    "                )\n",
    "    \n",
    "        \n",
    "    if revers==True:\n",
    "        for i in columns_df:\n",
    "            if i in drop_list:\n",
    "                pass\n",
    "                #print(i)\n",
    "            else:\n",
    "                #print(i)\n",
    "                test_data.drop(\n",
    "                    i,  # список колонок або рядків, які потрібно видалити\n",
    "                    axis=1,  # видалення рядків відбувається аналогічно, щоб видалити саме колонки, вибираємо відповідну вісь\n",
    "                    inplace=True  # видалення \"на місці\", без надання нової змінної)\n",
    "                )\n",
    "                \n",
    "            \n",
    "    return test_data.copy()\n",
    "\n",
    "def replase_M_to_Max_int(weather_data, replase_column, date_type):\n",
    "    #df=weather_data.copy()\n",
    "    try:\n",
    "        weather_data[replase_column].unique()\n",
    "        weather_data[replase_column]=weather_data[replase_column].replace(regex=['M'], value='-1000').astype(str).astype(date_type)\n",
    "        \n",
    "        M=weather_data[replase_column].max()\n",
    "        \n",
    "        weather_data.loc[(weather_data[replase_column] ==-1000), replase_column] = M\n",
    "        print(f'{replase_column}_{M} {weather_data[replase_column].unique()}')\n",
    "    except Exception as _ex:\n",
    "        print(f\"[{replase_column}] Error\", _ex)\n",
    "    return weather_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeSum\n",
      "6.86\n",
      "Heat_29 [ 0 14 13  9  7 29  5  6  4 10  8 12  3  2  1 15 16 19 17 20 11 18 21 25\n",
      " 24 27 26 23 28 22]\n",
      "Cool_29 [ 2  3  0 29  5  4  6  8  7  9 10 13 11 12  1 15 16 17 14 20 19 18 21 22\n",
      " 24 27 23 26 28 25]\n",
      "Depart_23 [ 14  23  -3   2   4   5  10  12  13  -2  15  11  -4  -6   8  -5   1   9\n",
      "   6  -9  -8   3   0  -1  -7   7 -14  18  16  22  21  20 -10 -16  17 -12\n",
      " -11 -15 -17  19 -13]\n",
      "Tavg_94 [67 68 51 52 56 58 94 60 59 65 70 69 71 61 55 57 73 72 53 62 63 74 75 78\n",
      " 76 77 66 80 64 81 82 79 85 84 83 50 49 46 48 45 54 47 44 40 41 38 39 42\n",
      " 37 43 86 87 89 92 88 91 93 90 36]\n",
      "WetBulb_78 [56 57 47 48 50 49 46 54 53 62 63 60 61 51 59 58 43 44 45 65 66 67 64 52\n",
      " 55 69 68 70 72 71 73 74 76 42 39 40 41 35 33 34 78 75 36 32 38 77 37]\n",
      "StnPressure_29.86 [29.1  29.18 29.38 29.44 29.39 29.46 29.31 29.36 29.4  29.57 29.62 29.29\n",
      " 29.21 29.28 29.2  29.26 29.33 29.49 29.54 29.55 29.23 29.13 29.19 29.53\n",
      " 29.6  29.34 29.41 29.47 29.51 29.42 29.43 29.25 29.03 28.82 28.87 28.88\n",
      " 29.16 29.07 28.84 28.91 29.24 29.86 29.3  29.12 29.45 29.56 29.32 29.05\n",
      " 29.11 29.06 29.22 29.08 29.14 29.37 29.35 29.15 29.17 29.48 29.52 29.27\n",
      " 29.5  28.59 28.67 28.75 29.02 29.79 29.63 29.7  28.95 29.01 28.79 28.85\n",
      " 28.97 28.89 28.94 28.93 28.98 28.96 29.   29.66 29.09 28.9  29.04 29.59\n",
      " 29.65 29.58 29.61 29.64 29.71 29.67 28.8  28.73 29.68 28.74 28.55 28.63\n",
      " 28.92 28.99 28.81 28.71 28.69 28.77 28.83]\n",
      "AvgSpeed_26.3 [ 9.2  9.6 13.4 11.9 13.2 10.8 10.4 12.  11.5 15.  14.5 10.5  9.9  5.8\n",
      "  5.4  6.2  5.9  4.1  3.9 12.9 12.8 13.   8.1  7.6 17.3 14.6 12.3 12.2\n",
      " 11.8 11.3  7.5  5.5 11.4 10.7  9.7  8.2  7.8 10.2 10.6 11.2 15.2  8.8\n",
      "  7.2  9.5  5.3  5.2  6.5  7.4 10.1  6.4  6.7 23.1 20.7 13.8 12.4  5.\n",
      "  4.7  5.6  6.9  8.4 10.   8.6 26.3  6.8  4.9  6.1  6.3 15.1 12.6  7.7\n",
      "  8.7  9.   8.   6.   7.1  8.5 12.5 13.3  8.3  7.3 13.1 12.7 10.9 11.1\n",
      " 13.9  6.6 14.4  9.1  3.3  3.5  4.   7.   9.4  7.9  5.7  4.3  4.6  3.7\n",
      " 11.7  4.4 12.1 13.5 13.7 11.   9.8  8.9 10.3 15.5 18.9 17.2 16.7 18.\n",
      " 18.2 16.8 14.1 14.7  4.2  9.3 14.3 17.7 17.8 15.9 19.3 17.4  3.8  4.8\n",
      " 14.  21.5 19.5 16.3  5.1  3.6  3.2  4.5  2.9  3.1  2.7 18.4 16.4 14.8\n",
      " 11.6 13.6  2.4  2.6  3.4  3.   2.1 20.2 14.9 16.2 15.4 17.9 14.2 15.3\n",
      " 15.7 16.1 18.8 17.1 16.6 21.4 23.2 22.1 15.6 16.9  2.   2.3  1.7 19.9\n",
      " 17.6 18.5 18.1 16.  15.8  2.8  1.9 22.9 22.6]\n",
      "SeaLevel_30.53 [29.82 30.09 30.08 30.12 30.05 30.04 30.1  30.29 30.28 30.03 30.02 29.94\n",
      " 29.93 29.92 29.91 30.2  30.19 30.24 29.97 29.98 29.84 29.83 30.27 30.25\n",
      " 30.26 30.11 30.06 30.23 30.15 30.14 30.   29.99 29.9  29.77 29.76 29.56\n",
      " 29.54 29.52 29.51 29.79 29.78 29.81 29.55 29.85 30.07 30.16 30.53 29.96\n",
      " 29.95 30.13 30.21 30.22 29.88 30.01 29.8  29.89 29.74 29.87 29.86 30.18\n",
      " 30.17 29.34 29.44 29.45 29.71 29.72 30.52 30.4  30.41 29.67 29.53 29.69\n",
      " 29.61 29.64 29.63 29.66 29.7  30.34 30.33 29.62 29.6  29.75 29.68 29.73\n",
      " 30.31 30.3  30.32 30.37 30.39 29.59 29.65 30.35 30.36 29.48 30.38 29.5\n",
      " 29.25 29.23 29.46 29.43 29.47]\n"
     ]
    }
   ],
   "source": [
    "#weather_data\n",
    "\n",
    "weather_data=clear_data(weather_data, ['Water1'], revers=False)\n",
    "list_category=['CodeSum']\n",
    "weather_data=make_category (weather_data, list_category)    \n",
    "\n",
    "#Depth_2\n",
    "replase_column='Depth'\n",
    "weather_data[replase_column].unique()\n",
    "level_map = {'0': 0, 'M': 1}\n",
    "weather_data[replase_column] = weather_data[replase_column].map(level_map).astype(str).astype(int)\n",
    "#weather_data[replase_column].unique()\n",
    "\n",
    "\n",
    "#SnowFall\n",
    "replase_column='SnowFall'\n",
    "level_map = {'0.0': 0, 'M': 0.5, '  T':1,  '0.1':0.1}\n",
    "weather_data[replase_column] = weather_data[replase_column].map(level_map).astype(str).astype(float)\n",
    "weather_data[replase_column].unique()\n",
    "\n",
    "#Sunrise\n",
    "replase_column='Sunrise'\n",
    "weather_data[replase_column] =weather_data[replase_column] .replace(regex=['-'],value='0').astype(str).astype(int)\n",
    "#weather_data[replase_column].unique()\n",
    "\n",
    "#Sunset\n",
    "replase_column='Sunset'\n",
    "weather_data[replase_column] =weather_data[replase_column] .replace(regex=['-'],value='0').astype(str).astype(int)\n",
    "#weather_data[replase_column].unique()\n",
    "\n",
    "#PrecipTotal\n",
    "replase_column='PrecipTotal'\n",
    "weather_data[replase_column] =weather_data[replase_column] .replace(regex=['M'],value='-1000')\n",
    "M=weather_data[replase_column].max()\n",
    "weather_data.loc[(weather_data[replase_column] =='-1000'), replase_column] = M\n",
    "print (M)\n",
    "\n",
    "\n",
    "\n",
    "weather_data[replase_column] =weather_data[replase_column] .replace(regex=['  T'],value='0')\n",
    "'''T=weather_data[replase_column].min()\n",
    "print (f'{T}_{weather_data.loc[(weather_data[replase_column] ==1000), replase_column]}')\n",
    "weather_data.loc[(weather_data[replase_column] ==1000), replase_column] = weather_data[replase_column].min()'''\n",
    "weather_data['1']=weather_data[replase_column].astype(str).astype(float)\n",
    "\n",
    "\n",
    "clear_data(weather_data, [replase_column], revers=False)\n",
    "\n",
    "weather_data.rename(\n",
    "            columns={'1': replase_column,  # колонка \"SibSp\" буде перейменована на \"SiblingsSpouses\"\n",
    "                    }, inplace=True  # покажчик того, що зміни вносяться до існуючої таблиці\n",
    "        )\n",
    "\n",
    "#weather_data[replase_column].unique()\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'Heat', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'Cool', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'Depart', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'Tavg', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'WetBulb', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'StnPressure', float)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'AvgSpeed', float)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'SeaLevel', float)\n",
    "weather_data=add_datetime(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trap</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Date</th>\n",
       "      <th>NumMosquitos</th>\n",
       "      <th>WnvPresent</th>\n",
       "      <th>AddressAccuracy</th>\n",
       "      <th>RESTUANS</th>\n",
       "      <th>PIPIENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Trap, Latitude, Longitude, Date, NumMosquitos, WnvPresent, AddressAccuracy, RESTUANS, PIPIENS]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3427 entries, 0 to 50\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Trap             3427 non-null   object \n",
      " 1   Latitude         3427 non-null   float64\n",
      " 2   Longitude        3427 non-null   float64\n",
      " 3   Date             3427 non-null   object \n",
      " 4   NumMosquitos     3427 non-null   int64  \n",
      " 5   WnvPresent       3427 non-null   int64  \n",
      " 6   AddressAccuracy  3427 non-null   int64  \n",
      " 7   RESTUANS         3427 non-null   int64  \n",
      " 8   PIPIENS          3427 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 267.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#train_data\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def iter_days(draft_year, draft_month):\n",
    "    dt = datetime(draft_year, draft_month, 1)\n",
    "    while dt.year == draft_year and  dt.month == draft_month:\n",
    "        yield dt\n",
    "        dt += timedelta(days=1)\n",
    "\n",
    "\n",
    "train_data=add_datetime(train_data)\n",
    "train_data['RESTUANS']=train_data['Species'].str.contains('True').astype(str).astype(bool)\n",
    "train_data['PIPIENS']=train_data['Species'].str.contains('True').astype(str).astype(bool)\n",
    "train_data['Trap_1']=np.power(train_data['Latitude'], 2)+np.power(train_data['Longitude'], 2)\n",
    "\n",
    "#draft_year_list={2007, 2009, 2013}\n",
    "#draft_month_list={6, 7, 8, 9}\n",
    "draft_year_list={2007, 2009, 2013}\n",
    "draft_month_list={6, 7, 8, 9}\n",
    "frames=[]\n",
    "for draft_year in draft_year_list:\n",
    "    data_year=train_data[train_data['year']==draft_year].copy()\n",
    "    #print(draft_year)\n",
    "    for draft_month in draft_month_list:\n",
    "        #print(draft_month)\n",
    "        train_data_month=data_year[(data_year['month']==draft_month)]\n",
    "        for dt in iter_days(draft_year, draft_month):\n",
    "            train_data_day=concat_train_data(train_data_month[(train_data_month['day']==dt.day)])\n",
    "            if train_data_day.shape[0]>0:\n",
    "                train_data_day.set_index('Date', inplace=False)\n",
    "                frames.append(train_data_day)\n",
    "\n",
    "result = pd.concat(frames, axis=0)\n",
    "result.reset_index()\n",
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 988 entries, 0 to 61\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Trap_1           988 non-null    float64\n",
      " 1   Latitude         988 non-null    float64\n",
      " 2   Longitude        988 non-null    float64\n",
      " 3   Date             988 non-null    object \n",
      " 4   AddressAccuracy  988 non-null    int64  \n",
      " 5   RESTUANS         988 non-null    int64  \n",
      " 6   PIPIENS          988 non-null    int64  \n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 61.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#test_truncated_data\n",
    "def concat_truncated_data(train_data):\n",
    "    Trap=group_data(train_data, 'Trap_1', 'Latitude', 'min')\n",
    "    Longitude=group_data(train_data, 'Trap_1', 'Longitude', 'min')\n",
    "    #NumMosquitos=group_data(train_data, 'Trap', 'NumMosquitos', 'sum')\n",
    "    #WnvPresent=group_data(train_data, 'Trap', 'WnvPresent', 'sum')\n",
    "    AddressAccuracy=group_data(train_data, 'Trap_1', 'AddressAccuracy', 'min')\n",
    "    RESTUANS=group_data(train_data, 'Trap_1', 'RESTUANS', 'sum')\n",
    "    PIPIENS=group_data(train_data, 'Trap_1', 'PIPIENS', 'sum')\n",
    "    Date_Min=group_data(train_data, 'Trap_1', 'Date', 'min')\n",
    "    #Date_Max=group_data(train_data, 'Trap', 'Date', 'max')\n",
    "    \n",
    "    frames = [Trap, Longitude, Date_Min, AddressAccuracy, RESTUANS, PIPIENS]\n",
    "    result = pd.concat(frames, axis=1)\n",
    "    result.reset_index(inplace=True)\n",
    "    return result.copy()\n",
    "\n",
    "test_truncated_data=add_datetime(test_truncated_data)\n",
    "test_truncated_data['RESTUANS']=test_truncated_data['Species'].str.contains('True').astype(str).astype(bool)\n",
    "test_truncated_data['PIPIENS']=test_truncated_data['Species'].str.contains('True').astype(str).astype(bool)\n",
    "test_truncated_data['Trap_1']=np.power(test_truncated_data['Latitude'], 2)+np.power(test_truncated_data['Longitude'], 2)\n",
    "#draft_year_list={2007, 2009, 2013}\n",
    "#draft_month_list={6, 7, 8, 9}\n",
    "\n",
    "draft_year_list={2011}\n",
    "draft_month_list={6, 7, 8, 9}\n",
    "frames=[]\n",
    "for draft_year in draft_year_list:\n",
    "    data_year=test_truncated_data[test_truncated_data['year']==draft_year].copy()\n",
    "    #print(draft_year)\n",
    "    for draft_month in draft_month_list:\n",
    "        #print(draft_month)\n",
    "        train_data_month=data_year[(data_year['month']==draft_month)]\n",
    "        for dt in iter_days(draft_year, draft_month):\n",
    "            test_truncated_data_day=concat_truncated_data(train_data_month[(train_data_month['day']==dt.day)])\n",
    "            if test_truncated_data_day.shape[0]>0:\n",
    "                test_truncated_data_day.set_index('Date', inplace=False)\n",
    "                frames.append(test_truncated_data_day)\n",
    "\n",
    "test_truncated_data_result = pd.concat(frames, axis=0)\n",
    "test_truncated_data_result.reset_index()\n",
    "test_truncated_data_result['Date']=np.datetime_as_string(test_truncated_data_result['Date'], unit='D')\n",
    "#.astype(object)\n",
    "test_truncated_data_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3427 entries, 0 to 3426\n",
      "Data columns (total 51 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Trap             3427 non-null   object \n",
      " 1   Latitude         3427 non-null   float64\n",
      " 2   Longitude        3427 non-null   float64\n",
      " 3   Date             3427 non-null   object \n",
      " 4   NumMosquitos     3427 non-null   int64  \n",
      " 5   WnvPresent       3427 non-null   int64  \n",
      " 6   AddressAccuracy  3427 non-null   int64  \n",
      " 7   RESTUANS         3427 non-null   int64  \n",
      " 8   PIPIENS          3427 non-null   int64  \n",
      " 9   Station_1        3427 non-null   int64  \n",
      " 10  Tmax_1           3427 non-null   int64  \n",
      " 11  Tmin_1           3427 non-null   int64  \n",
      " 12  Tavg_1           3427 non-null   int32  \n",
      " 13  Depart_1         3427 non-null   int32  \n",
      " 14  DewPoint_1       3427 non-null   int64  \n",
      " 15  WetBulb_1        3427 non-null   int32  \n",
      " 16  Heat_1           3427 non-null   int32  \n",
      " 17  Cool_1           3427 non-null   int32  \n",
      " 18  Sunrise_1        3427 non-null   int32  \n",
      " 19  Sunset_1         3427 non-null   int32  \n",
      " 20  Depth_1          3427 non-null   int32  \n",
      " 21  SnowFall_1       3427 non-null   float64\n",
      " 22  StnPressure_1    3427 non-null   float64\n",
      " 23  SeaLevel_1       3427 non-null   float64\n",
      " 24  ResultSpeed_1    3427 non-null   float64\n",
      " 25  ResultDir_1      3427 non-null   int64  \n",
      " 26  AvgSpeed_1       3427 non-null   float64\n",
      " 27  PrecipTotal_1    3427 non-null   float64\n",
      " 28  day_1            3427 non-null   int64  \n",
      " 29  weekday_1        3427 non-null   int64  \n",
      " 30  month_1          3427 non-null   int64  \n",
      " 31  year_1           3427 non-null   int64  \n",
      " 32  Station_2        3427 non-null   int64  \n",
      " 33  Tmax_2           3427 non-null   int64  \n",
      " 34  Tmin_2           3427 non-null   int64  \n",
      " 35  Tavg_2           3427 non-null   int32  \n",
      " 36  Depart_2         3427 non-null   int32  \n",
      " 37  DewPoint_2       3427 non-null   int64  \n",
      " 38  WetBulb_2        3427 non-null   int32  \n",
      " 39  Heat_2           3427 non-null   int32  \n",
      " 40  Cool_2           3427 non-null   int32  \n",
      " 41  Sunrise_2        3427 non-null   int32  \n",
      " 42  Sunset_2         3427 non-null   int32  \n",
      " 43  Depth_2          3427 non-null   int32  \n",
      " 44  SnowFall_2       3427 non-null   float64\n",
      " 45  StnPressure_2    3427 non-null   float64\n",
      " 46  SeaLevel_2       3427 non-null   float64\n",
      " 47  ResultSpeed_2    3427 non-null   float64\n",
      " 48  ResultDir_2      3427 non-null   int64  \n",
      " 49  AvgSpeed_2       3427 non-null   float64\n",
      " 50  PrecipTotal_2    3427 non-null   float64\n",
      "dtypes: float64(14), int32(16), int64(19), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge weather_data and test_data\n",
    "\n",
    "weather_1=weather_data[weather_data['Station']==1].copy()\n",
    "weather_1.set_index('Date', inplace=True)\n",
    "weather_2=weather_data[weather_data['Station']==2].copy()\n",
    "weather_2.set_index('Date', inplace=True)\n",
    "\n",
    "weather=weather_1.merge(weather_2,\n",
    "    #weather_1, left_on='Date', right_on='Date')\n",
    "    how='inner',\n",
    "    #on=None, \n",
    "    left_on='Date', right_on='Date', \n",
    "    #left_index=True, right_index=True,\n",
    "    #, sort=False,\n",
    "    suffixes=('_1', '_2'), copy=True\n",
    "    #, indicator=False, validate=None\n",
    ")\n",
    "test_data=result.merge(weather,\n",
    "    #weather_1, left_on='Date', right_on='Date')\n",
    "    how='inner',\n",
    "    #on=None, \n",
    "    left_on='Date', right_on='Date', \n",
    "    #left_index=True, right_index=True,\n",
    "    #, sort=False,\n",
    "    #suffixes=('_x', '_y'), copy=True\n",
    "    #, indicator=False, validate=None\n",
    ")\n",
    "\n",
    "test_truncated_data=test_truncated_data_result.merge(weather,\n",
    "    #weather_1, left_on='Date', right_on='Date')\n",
    "    how='inner',\n",
    "    #on=None, \n",
    "    left_on='Date', right_on='Date', \n",
    "    #left_index=True, right_index=True,\n",
    "    #, sort=False,\n",
    "    #suffixes=('_x', '_y'), copy=True\n",
    "    #, indicator=False, validate=None\n",
    ")\n",
    "\n",
    "#test_truncated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 'CodeSum_1'\n",
      "Error 'CodeSum_2'\n",
      "Error 'CodeSum_1'\n",
      "Error 'CodeSum_2'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 988 entries, 0 to 987\n",
      "Data columns (total 49 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Trap_1           988 non-null    float64\n",
      " 1   Latitude         988 non-null    float64\n",
      " 2   Longitude        988 non-null    float64\n",
      " 3   Date             988 non-null    object \n",
      " 4   AddressAccuracy  988 non-null    int64  \n",
      " 5   RESTUANS         988 non-null    int64  \n",
      " 6   PIPIENS          988 non-null    int64  \n",
      " 7   Station_1        988 non-null    int64  \n",
      " 8   Tmax_1           988 non-null    int64  \n",
      " 9   Tmin_1           988 non-null    int64  \n",
      " 10  Tavg_1           988 non-null    int32  \n",
      " 11  Depart_1         988 non-null    int32  \n",
      " 12  DewPoint_1       988 non-null    int64  \n",
      " 13  WetBulb_1        988 non-null    int32  \n",
      " 14  Heat_1           988 non-null    int32  \n",
      " 15  Cool_1           988 non-null    int32  \n",
      " 16  Sunrise_1        988 non-null    int32  \n",
      " 17  Sunset_1         988 non-null    int32  \n",
      " 18  Depth_1          988 non-null    int32  \n",
      " 19  SnowFall_1       988 non-null    float64\n",
      " 20  StnPressure_1    988 non-null    float64\n",
      " 21  SeaLevel_1       988 non-null    float64\n",
      " 22  ResultSpeed_1    988 non-null    float64\n",
      " 23  ResultDir_1      988 non-null    int64  \n",
      " 24  AvgSpeed_1       988 non-null    float64\n",
      " 25  PrecipTotal_1    988 non-null    float64\n",
      " 26  day_1            988 non-null    int64  \n",
      " 27  weekday_1        988 non-null    int64  \n",
      " 28  month_1          988 non-null    int64  \n",
      " 29  year_1           988 non-null    int64  \n",
      " 30  Station_2        988 non-null    int64  \n",
      " 31  Tmax_2           988 non-null    int64  \n",
      " 32  Tmin_2           988 non-null    int64  \n",
      " 33  Tavg_2           988 non-null    int32  \n",
      " 34  Depart_2         988 non-null    int32  \n",
      " 35  DewPoint_2       988 non-null    int64  \n",
      " 36  WetBulb_2        988 non-null    int32  \n",
      " 37  Heat_2           988 non-null    int32  \n",
      " 38  Cool_2           988 non-null    int32  \n",
      " 39  Sunrise_2        988 non-null    int32  \n",
      " 40  Sunset_2         988 non-null    int32  \n",
      " 41  Depth_2          988 non-null    int32  \n",
      " 42  SnowFall_2       988 non-null    float64\n",
      " 43  StnPressure_2    988 non-null    float64\n",
      " 44  SeaLevel_2       988 non-null    float64\n",
      " 45  ResultSpeed_2    988 non-null    float64\n",
      " 46  ResultDir_2      988 non-null    int64  \n",
      " 47  AvgSpeed_2       988 non-null    float64\n",
      " 48  PrecipTotal_2    988 non-null    float64\n",
      "dtypes: float64(15), int32(16), int64(17), object(1)\n",
      "memory usage: 324.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#test_data clear\n",
    "def clear_dtype(weather_data, drop_dtype_list):\n",
    "    for col in weather_data:\n",
    "        if str(weather_data[col].dtypes) in drop_dtype_list:\n",
    "            try:\n",
    "                weather_data.drop(\n",
    "                    weather_data[col].name,  # список колонок або рядків, які потрібно видалити\n",
    "                    axis=1,  # видалення рядків відбувається аналогічно, щоб видалити саме колонки, вибираємо відповідну вісь\n",
    "                    inplace=True  # видалення \"на місці\", без надання нової змінної\n",
    "                )\n",
    "                #X_Data=clear_data(X_Data, X_Data[col].name, revers=False)\n",
    "                print(f'{col}_{weather_data[col].name}_{weather_data[col].dtypes}')\n",
    "                return weather_data.copy()\n",
    "            except Exception as _ex:\n",
    "                print(f\"Error\", _ex)\n",
    "                \n",
    "                \n",
    "drop_list=['year_2', 'month_2', 'weekday_2', 'day_2']\n",
    "test_data=clear_data(test_data, drop_list, revers=False)\n",
    "test_truncated_data=clear_data(test_truncated_data, drop_list, revers=False)\n",
    "#drop_dtype_list=['bool', 'category', 'int64' ,'int32', 'float64', ]\n",
    "drop_dtype_list=['category']                \n",
    "clear_dtype(test_data, drop_dtype_list)\n",
    "clear_dtype(test_truncated_data, drop_dtype_list)\n",
    "test_truncated_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_drop_list=['NumMosquitos', 'WnvPresent', 'RESTUANS', 'PIPIENS', 'Trap', 'Date', 'Latitude', 'Longitude']\n",
    "\n",
    "X_drop_list=['NumMosquitos', 'WnvPresent', 'Trap', 'Date']\n",
    "X_Data=clear_data(test_data.copy(), X_drop_list, revers=False)\n",
    "\n",
    "Y_Data=clear_data(test_data.copy(), X_drop_list, revers=True)\n",
    "Y_Data=clear_data(Y_Data, ['Trap', 'Date', 'WnvPresent'], revers=False)\n",
    "\n",
    "X_test_truncated_data=clear_data(test_truncated_data.copy(), X_drop_list, revers=False)\n",
    "\n",
    "\n",
    "X_drop_list=['Latitude', 'Longitude', 'month_1', 'day_1']\n",
    "#X_Data=clear_data(test_data.copy(), X_drop_list, revers=True)\n",
    "#X_test_truncated_data=clear_data(test_data.copy(), X_drop_list, revers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3427 entries, 0 to 3426\n",
      "Data columns (total 47 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Latitude         3427 non-null   float64\n",
      " 1   Longitude        3427 non-null   float64\n",
      " 2   AddressAccuracy  3427 non-null   int64  \n",
      " 3   RESTUANS         3427 non-null   int64  \n",
      " 4   PIPIENS          3427 non-null   int64  \n",
      " 5   Station_1        3427 non-null   int64  \n",
      " 6   Tmax_1           3427 non-null   int64  \n",
      " 7   Tmin_1           3427 non-null   int64  \n",
      " 8   Tavg_1           3427 non-null   int32  \n",
      " 9   Depart_1         3427 non-null   int32  \n",
      " 10  DewPoint_1       3427 non-null   int64  \n",
      " 11  WetBulb_1        3427 non-null   int32  \n",
      " 12  Heat_1           3427 non-null   int32  \n",
      " 13  Cool_1           3427 non-null   int32  \n",
      " 14  Sunrise_1        3427 non-null   int32  \n",
      " 15  Sunset_1         3427 non-null   int32  \n",
      " 16  Depth_1          3427 non-null   int32  \n",
      " 17  SnowFall_1       3427 non-null   float64\n",
      " 18  StnPressure_1    3427 non-null   float64\n",
      " 19  SeaLevel_1       3427 non-null   float64\n",
      " 20  ResultSpeed_1    3427 non-null   float64\n",
      " 21  ResultDir_1      3427 non-null   int64  \n",
      " 22  AvgSpeed_1       3427 non-null   float64\n",
      " 23  PrecipTotal_1    3427 non-null   float64\n",
      " 24  day_1            3427 non-null   int64  \n",
      " 25  weekday_1        3427 non-null   int64  \n",
      " 26  month_1          3427 non-null   int64  \n",
      " 27  year_1           3427 non-null   int64  \n",
      " 28  Station_2        3427 non-null   int64  \n",
      " 29  Tmax_2           3427 non-null   int64  \n",
      " 30  Tmin_2           3427 non-null   int64  \n",
      " 31  Tavg_2           3427 non-null   int32  \n",
      " 32  Depart_2         3427 non-null   int32  \n",
      " 33  DewPoint_2       3427 non-null   int64  \n",
      " 34  WetBulb_2        3427 non-null   int32  \n",
      " 35  Heat_2           3427 non-null   int32  \n",
      " 36  Cool_2           3427 non-null   int32  \n",
      " 37  Sunrise_2        3427 non-null   int32  \n",
      " 38  Sunset_2         3427 non-null   int32  \n",
      " 39  Depth_2          3427 non-null   int32  \n",
      " 40  SnowFall_2       3427 non-null   float64\n",
      " 41  StnPressure_2    3427 non-null   float64\n",
      " 42  SeaLevel_2       3427 non-null   float64\n",
      " 43  ResultSpeed_2    3427 non-null   float64\n",
      " 44  ResultDir_2      3427 non-null   int64  \n",
      " 45  AvgSpeed_2       3427 non-null   float64\n",
      " 46  PrecipTotal_2    3427 non-null   float64\n",
      "dtypes: float64(14), int32(16), int64(17)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Trap_1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [72], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m train_predictions \u001b[38;5;241m=\u001b[39m mdl\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m     19\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m mdl\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 20\u001b[0m truncated_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_truncated_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mПомилка на навчальному наборі: \u001b[39m\u001b[38;5;124m'\u001b[39m, mean_squared_error(y_train, train_predictions))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mПомилка на тестовому наборі: \u001b[39m\u001b[38;5;124m'\u001b[39m, mean_squared_error(y_test, test_predictions))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_base.py:355\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_base.py:338\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    336\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 338\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:518\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    455\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    460\u001b[0m ):\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    522\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    523\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:451\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    447\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     )\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Trap_1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_Data,  # перший масив, який потрібно розділити\n",
    "    Y_Data,  # другий масив, який потрібно роздолити\n",
    "    test_size=0.2,  # розмір меншої групи (20% від загальної кількості даних)\n",
    "    random_state=42  # фіксація випадкового стану: тепер при перезапуску групи будуть однаковими\n",
    ")\n",
    "\n",
    "    # формальність для того, щоб не бачити попередження про зміни на зрізі з таблиці\n",
    "X_train, X_test = X_train.copy(), X_test.copy()\n",
    "    # побудуємо модель\n",
    "mdl = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # оцінимо точність моделі\n",
    "train_predictions = mdl.predict(X_train)\n",
    "test_predictions = mdl.predict(X_test)\n",
    "truncated_predictions = mdl.predict(X_test_truncated_data)\n",
    "\n",
    "\n",
    "print('Помилка на навчальному наборі: ', mean_squared_error(y_train, train_predictions))\n",
    "print('Помилка на тестовому наборі: ', mean_squared_error(y_test, test_predictions))\n",
    "score = mdl.score(X_test, y_test)\n",
    "print(score)\n",
    "#print(mdl.score(X_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trap</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Date</th>\n",
       "      <th>AddressAccuracy</th>\n",
       "      <th>RESTUANS</th>\n",
       "      <th>PIPIENS</th>\n",
       "      <th>Station_1</th>\n",
       "      <th>Tmax_1</th>\n",
       "      <th>Tmin_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunset_2</th>\n",
       "      <th>Depth_2</th>\n",
       "      <th>SnowFall_2</th>\n",
       "      <th>StnPressure_2</th>\n",
       "      <th>SeaLevel_2</th>\n",
       "      <th>ResultSpeed_2</th>\n",
       "      <th>ResultDir_2</th>\n",
       "      <th>AvgSpeed_2</th>\n",
       "      <th>PrecipTotal_2</th>\n",
       "      <th>NumMosquitos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9398.504385</td>\n",
       "      <td>41.659112</td>\n",
       "      <td>-87.538693</td>\n",
       "      <td>2011-08-05</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.630736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9399.712148</td>\n",
       "      <td>41.680946</td>\n",
       "      <td>-87.535198</td>\n",
       "      <td>2011-08-05</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.736347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9406.686006</td>\n",
       "      <td>41.740641</td>\n",
       "      <td>-87.546587</td>\n",
       "      <td>2011-08-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.602630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9407.017188</td>\n",
       "      <td>41.704572</td>\n",
       "      <td>-87.565666</td>\n",
       "      <td>2011-08-05</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85.207640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9410.408757</td>\n",
       "      <td>41.673408</td>\n",
       "      <td>-87.599862</td>\n",
       "      <td>2011-08-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-32.011635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>9469.661860</td>\n",
       "      <td>42.008314</td>\n",
       "      <td>-87.777921</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.34</td>\n",
       "      <td>29.96</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>57.453058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>9471.532050</td>\n",
       "      <td>41.973845</td>\n",
       "      <td>-87.805059</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.34</td>\n",
       "      <td>29.96</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>56.178857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>9473.966292</td>\n",
       "      <td>41.944869</td>\n",
       "      <td>-87.832763</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.34</td>\n",
       "      <td>29.96</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>56.444459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>9486.634722</td>\n",
       "      <td>41.974689</td>\n",
       "      <td>-87.890615</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.34</td>\n",
       "      <td>29.96</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>533.130428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>9492.316779</td>\n",
       "      <td>41.957799</td>\n",
       "      <td>-87.930995</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.34</td>\n",
       "      <td>29.96</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>136.353815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Trap   Latitude  Longitude        Date  AddressAccuracy  RESTUANS  \\\n",
       "0    9398.504385  41.659112 -87.538693  2011-08-05                8         3   \n",
       "1    9399.712148  41.680946 -87.535198  2011-08-05                8         3   \n",
       "2    9406.686006  41.740641 -87.546587  2011-08-05                5         2   \n",
       "3    9407.017188  41.704572 -87.565666  2011-08-05                8         4   \n",
       "4    9410.408757  41.673408 -87.599862  2011-08-05                5         1   \n",
       "..           ...        ...        ...         ...              ...       ...   \n",
       "983  9469.661860  42.008314 -87.777921  2011-07-29                9         3   \n",
       "984  9471.532050  41.973845 -87.805059  2011-07-29                9         3   \n",
       "985  9473.966292  41.944869 -87.832763  2011-07-29                8         3   \n",
       "986  9486.634722  41.974689 -87.890615  2011-07-29                9        15   \n",
       "987  9492.316779  41.957799 -87.930995  2011-07-29                5         5   \n",
       "\n",
       "     PIPIENS  Station_1  Tmax_1  Tmin_1  ...  Sunset_2  Depth_2  SnowFall_2  \\\n",
       "0          3          1      83      69  ...         0        1         0.5   \n",
       "1          3          1      83      69  ...         0        1         0.5   \n",
       "2          2          1      83      69  ...         0        1         0.5   \n",
       "3          4          1      83      69  ...         0        1         0.5   \n",
       "4          1          1      83      69  ...         0        1         0.5   \n",
       "..       ...        ...     ...     ...  ...       ...      ...         ...   \n",
       "983        3          1      86      71  ...         0        1         0.5   \n",
       "984        3          1      86      71  ...         0        1         0.5   \n",
       "985        3          1      86      71  ...         0        1         0.5   \n",
       "986       15          1      86      71  ...         0        1         0.5   \n",
       "987        5          1      86      71  ...         0        1         0.5   \n",
       "\n",
       "     StnPressure_2  SeaLevel_2  ResultSpeed_2  ResultDir_2  AvgSpeed_2  \\\n",
       "0            29.26       29.91            5.2            7         6.0   \n",
       "1            29.26       29.91            5.2            7         6.0   \n",
       "2            29.26       29.91            5.2            7         6.0   \n",
       "3            29.26       29.91            5.2            7         6.0   \n",
       "4            29.26       29.91            5.2            7         6.0   \n",
       "..             ...         ...            ...          ...         ...   \n",
       "983          29.34       29.96            3.5            4         5.6   \n",
       "984          29.34       29.96            3.5            4         5.6   \n",
       "985          29.34       29.96            3.5            4         5.6   \n",
       "986          29.34       29.96            3.5            4         5.6   \n",
       "987          29.34       29.96            3.5            4         5.6   \n",
       "\n",
       "     PrecipTotal_2  NumMosquitos  \n",
       "0             0.00     46.630736  \n",
       "1             0.00     46.736347  \n",
       "2             0.00     10.602630  \n",
       "3             0.00     85.207640  \n",
       "4             0.00    -32.011635  \n",
       "..             ...           ...  \n",
       "983           0.36     57.453058  \n",
       "984           0.36     56.178857  \n",
       "985           0.36     56.444459  \n",
       "986           0.36    533.130428  \n",
       "987           0.36    136.353815  \n",
       "\n",
       "[988 rows x 50 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truncated_data['NumMosquitos']=truncated_predictions\n",
    "'''test_truncated_data['NumMosquitos'].replace(regex=['['],value='')\n",
    "test_truncated_data['NumMosquitos'].replace(regex=[']'],value='')'''\n",
    "test_truncated_data\n",
    "#test_truncated_data['NumMosquitos'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# навчальні дані\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m92\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# розмір батча\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# кількість епох навчання\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# дані для валідації\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train, y=y_train,  # навчальні дані\n",
    "    batch_size=92,  # розмір батча\n",
    "    epochs=300,  # кількість епох навчання\n",
    "    validation_data=(X_test, y_test)  # дані для валідації\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = set(df.columns) - set(categorical_features)\n",
    "scaler = MinMaxScaler()\n",
    "df_norm = df.copy()\n",
    "df_norm[list(continuous_features)] = scaler.fit_transform(df[list(continuous_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# будуємо модель у вигляді дерева\n",
    "mdl = DecisionTreeClassifier(max_depth=3).fit(X_train, y_train)\n",
    "# оцінимо якість моделі\n",
    "predictions = mdl.predict_proba(X_test)\n",
    "#auc = roc_auc_score(y_test, predictions, average='macro', multi_class='ovr')\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\functional.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "# фіксація випадкового стану\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "model = Sequential()  # ініціалізація порожньої моделі\n",
    "\n",
    "# додамо один перцептрон у модель\n",
    "model.add(Dense(\n",
    "    units=1,  # кількість перцептронів\n",
    "    activation='sigmoid'  # функція активації: перетворення на виході моделі\n",
    "))\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.01),  # алгоритм оптимізації та швидкість навчання\n",
    "    loss='binary_crossentropy',  # функція втрат (та сама, що в логістичної регресії)\n",
    "    metrics=['accuracy']  # додаткова метрика якості моделі\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_name, coef_value in zip(X_train.columns, mdl.coef_):\n",
    "    print(var_name)\n",
    "    \n",
    "print(f'constant term: {var_name}', mdl.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centr_map():\n",
    "    map_ = folium.Map(location=[train_data['Latitude'].mean(),  train_data['Longitude'].mean()],\n",
    "               tiles=\"Stamen Terrain\", zoom_start=10, control_scale=False)\n",
    "\n",
    "    Station=folium.FeatureGroup(name='Station')\n",
    "    Station.add_to(map_)\n",
    "    Station.add_child(\n",
    "        folium.Marker([41.995,  -87.933],\n",
    "                      popup=\"CHICAGO O'HARE INTERNATIONAL AIRPORT\").add_to(map_))\n",
    "    Station.add_child(\n",
    "        folium.Marker(\n",
    "            [41.786,  -88.089163], popup=\"CHICAGO MIDWAY INTL ARPT\").add_to(map_))\n",
    "    return map_ \n",
    "\n",
    "map_=centr_map()\n",
    "\n",
    "\n",
    "\n",
    "df=spray_data\n",
    "time_index = list(spray_data['Date'].sort_values().astype('str').unique())\n",
    "\n",
    "\n",
    "df['Date'] = df['Date'].sort_values(ascending=True)\n",
    "data = []\n",
    "\n",
    "for _, d in df.groupby('Date'):\n",
    "    #print(f'{row}')\n",
    "    data.append([[row['Latitude'], row['Longitude'], 1] for _, row in d.iterrows()])\n",
    "\n",
    "hm = plugins.HeatMapWithTime(\n",
    "    data,\n",
    "    name=\"Spray\",\n",
    "    index=time_index,\n",
    "    auto_play=True,\n",
    "    min_opacity=0,\n",
    "    max_opacity=0.7,\n",
    "    #gradient={0.1:'blue', 0.25:'green', 0.5:'yelow', 0.75:'orange', 1:'red'} \n",
    ")\n",
    "hm.add_to(map_)\n",
    "\n",
    "folium.LayerControl().add_to(map_)\n",
    "map_.save(f\"sklearn_linear_model.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_=centr_map()\n",
    "\n",
    "\n",
    "\n",
    "df=test_data.copy()\n",
    "time_index = list(test_data['Date'].sort_values().astype('str').unique())\n",
    "\n",
    "\n",
    "df['Date'] = df['Date'].sort_values(ascending=True)\n",
    "data = []\n",
    "\n",
    "for _, d in df.groupby('Date'):\n",
    "    #print(f'{row}')\n",
    "    data.append([[row['Latitude'], row['Longitude'], row['NumMosquitos']] for _, row in d.iterrows()])\n",
    "\n",
    "test_data_hm = plugins.HeatMapWithTime(\n",
    "    data,\n",
    "    name=\"test_data\",\n",
    "    index=time_index,\n",
    "    auto_play=True,\n",
    "    min_opacity=0,\n",
    "    max_opacity=0.7,\n",
    "    #gradient={0.1:'blue', 0.25:'green', 0.5:'yelow', 0.75:'orange', 1:'red'} \n",
    ")\n",
    "test_data_hm.add_to(map_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(map_)\n",
    "map_.save(f\"test_data.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_markers(): \n",
    "    # train_data_point_map\n",
    "    draft_year_list={2007, 2009, 2013}\n",
    "    draft_month_list={6, 7, 8, 9}\n",
    "    geometry = geopandas.points_from_xy(train_data.Longitude, train_data.Latitude)\n",
    "    geo_df = geopandas.GeoDataFrame(\n",
    "        train_data, geometry=geometry\n",
    "    )\n",
    "    geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in geo_df.geometry]\n",
    "\n",
    "    wnvpresentsLayer=folium.FeatureGroup(name='wnvpresents')\n",
    "    wnvpresentsLayer.add_to(map_)\n",
    "\n",
    "    # Iterate through list and add a marker for each volcano, color-coded by its type.\n",
    "    i = 0\n",
    "    for coordinates in geo_df_list:\n",
    "        if (geo_df.month[i] == draft_month) and  (geo_df.year[i] == draft_year):\n",
    "            wnvpresents=int(train_data[(geo_df['Trap'] == geo_df.Trap[i]) & (geo_df['month']==draft_month) \n",
    "                       & (geo_df['year']==draft_year)]['WnvPresent'].sum())\n",
    "            if wnvpresents>0:\n",
    "                if geo_df.PIPIENS[i] == True:\n",
    "                    type_color = \"green\"\n",
    "                if (geo_df.RESTUANS[i] == True):\n",
    "                    type_color = \"red\"\n",
    "                    # Place the markers with the popup labels and data\n",
    "                wnvpresentsLayer.add_child(\n",
    "                    folium.Marker(\n",
    "                        location=coordinates,\n",
    "                        popup=geo_df.Trap[i]+ \"<br>\"\n",
    "                        +'wnvpresents '+ str(wnvpresents)+ \"<br>\"+'numMosquitos '+ str(numMosquitos(draft_year, draft_month)),\n",
    "                        icon=folium.Icon(color=\"%s\" % type_color)\n",
    "                        )\n",
    "                )\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datasetes():\n",
    "    fig = plt.figure()\n",
    "\n",
    "    plot_mas = test_truncated_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='blue', label='test_truncated_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True) \n",
    "\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plot_mas = weather_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='pink', label='weather_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    #fig2 = plt.figure()\n",
    "\n",
    "    plot_mas = train_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='green', label='train_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plot_mas = spray_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='red', label='spray_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plot_mas = test_truncated_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='red', label='test_truncated_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "\n",
    "plot_datasetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chat(_data, grop_list_, agr_colum, agr_func):\n",
    "    grop_list=[grop_list_]\n",
    "    agg_func_math = {\n",
    "        agr_colum: [agr_func]\n",
    "    }\n",
    "\n",
    "    plot_mas = _data.groupby(grop_list, group_keys=True, dropna=True).agg(agg_func_math).to_dict()[(agr_colum, agr_func)] \n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.bar(plot_mas.keys(), plot_mas.values())\n",
    "    plt.title(f'{grop_list_} {agr_colum} {agr_func} chart')\n",
    "    \n",
    "    plt.grid(True)   # лінії допоміжної сітки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_mas = train_data.groupby(['month'], group_keys=True,\n",
    "                              dropna=True).agg({'WnvPresent': ['sum']}).to_dict()[('WnvPresent', 'sum')] \n",
    "plt.bar(plot_mas.keys(), plot_mas.values(), color='red', label='WnvPresent sum month')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(False)   # лінії допоміжної сітки\n",
    "#Date\n",
    "fig = plt.figure()\n",
    "plot_mas = train_data.groupby(['Date'], group_keys=True,\n",
    "                              dropna=True).agg({'WnvPresent': ['sum']}).to_dict()[('WnvPresent', 'sum')] \n",
    "plt.bar(plot_mas.keys(), plot_mas.values(), color='red', label='WnvPresent sum Date')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(False)   # лінії допоміжної сітки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_adres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our key point when map open it\n",
    "map_ = folium.Map(location=[train_data_adres['Latitude'].mean(),  train_data_adres['Longitude'].mean()],\n",
    "               tiles=\"Stamen Terrain\", zoom_start=10, control_scale=False)\n",
    "\n",
    "for la,lo in train_data_adres:\n",
    "    folium.Marker(\n",
    "        location=[la,lo],\n",
    "        icon=folium.Icon(icon_color='white')\n",
    "    ).add_to(map2)\n",
    "# Plotting \n",
    "map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = folium.Map(location=[train_data_adres['Latitude'].mean(),  train_data_adres['Longitude'].mean()],\n",
    "               tiles=\"Stamen Terrain\", zoom_start=10, control_scale=False)\n",
    "\n",
    "folium.Marker(train_data_adres['Latitude','Longitude'], popup=train_data_adres['Trap']).add_to(map_)\n",
    "map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import folium\n",
    "#Station_1: CHICAGO O'HARE INTERNATIONAL AIRPORT Lat: 41.995 Lon: -87.933 Elev: 662 ft. above sea level\n",
    "#Station_2: CHICAGO MIDWAY INTL ARPT Lat: 41.786 Lon: -87.752 Elev: 612 ft. above sea level\n",
    "\n",
    "#m = folium.Map(location=[45.5236, -122.6750])\n",
    "#m = folium.Map(location=[42.391623, -88.089163], tiles=\"Stamen Terrain\", zoom_start=13)\n",
    "\n",
    "\n",
    "map_ = folium.Map(location=[spray_data['Latitude'].mean(),  spray_data['Longitude'].mean()],\n",
    "               tiles=\"Stamen Terrain\", zoom_start=10, control_scale=False)\n",
    "\n",
    "folium.Marker([41.995,  -87.933], popup=\"CHICAGO O'HARE INTERNATIONAL AIRPORT\").add_to(map_)\n",
    "folium.Marker([41.786,  -88.089163], popup=\"CHICAGO MIDWAY INTL ARPT\").add_to(map_)\n",
    "\n",
    "folium.CircleMarker(\n",
    "    location=[spray_data['Latitude'].mean(),  spray_data['Longitude'].mean()],\n",
    "    radius=10,\n",
    "    popup=\"spray_mean\",\n",
    "    color=\"#3186cc\",\n",
    "    fill=True,\n",
    "    fill_color=\"#3186cc\",\n",
    ").add_to(map_)\n",
    "\n",
    "\n",
    "#train_data_adres\n",
    "#for index, location_info in train_data.iterrows():\n",
    "#    folium.Marker([location_info[\"Latitude\"], location_info[\"Longitude\"]], popup=location_info[\"NumMosquitos\"]).add_to(map_)\n",
    "\n",
    "map_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
