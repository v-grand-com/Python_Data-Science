{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###### Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime as dt\n",
    "import folium\n",
    "from folium import plugins\n",
    "import geopandas\n",
    "from calendar import monthrange\n",
    "\n",
    "spray_data = pd.read_csv(\n",
    "    'Files/spray.csv',  # шлях до файлу, який містить дані\n",
    "    sep=',',  # роздільник стовпців\n",
    "    header=0  # номер рядка, що містить заголовок (якщо заголовка немає, можна передати None)\n",
    ")\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    'Files/train.csv',  # шлях до файлу, який містить дані\n",
    "    sep=',',  # роздільник стовпців\n",
    "    \n",
    "    header=0  # номер рядка, що містить заголовок (якщо заголовка немає, можна передати None)\n",
    ")\n",
    "\n",
    "weather_data = pd.read_csv(\n",
    "    'Files/weather.csv',  # шлях до файлу, який містить дані\n",
    "    sep=',',  # роздільник стовпців\n",
    "    header=0  # номер рядка, що містить заголовок (якщо заголовка немає, можна передати None)\n",
    ")\n",
    "\n",
    "test_truncated_data = pd.read_excel(\n",
    "    'Files/test_truncated.xlsx',\n",
    "    sheet_name='test_truncated',  # прочитати всі листи\n",
    "    usecols=\"A:J\"\n",
    "    #nrows=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime(train_data):\n",
    "    train_data['day']=pd.to_datetime(train_data.Date).dt.day\n",
    "    train_data['weekday']=pd.to_datetime(train_data.Date).dt.weekday\n",
    "    train_data['month']=pd.to_datetime(train_data.Date).dt.month\n",
    "    train_data['year']=pd.to_datetime(train_data.Date).dt.year\n",
    "    return train_data\n",
    "\n",
    "def bar_chat(_data, grop_list_, agr_colum, agr_func):\n",
    "    grop_list=[grop_list_]\n",
    "    agg_func_math = {\n",
    "        agr_colum: [agr_func]\n",
    "    }\n",
    "    plot_mas = _data.groupby(grop_list, group_keys=True, dropna=True).agg(agg_func_math).to_dict()[(agr_colum, agr_func)] \n",
    "    fig = plt.figure()\n",
    "    plt.bar(plot_mas.keys(), plot_mas.values())\n",
    "    plt.title(f'{grop_list_} {agr_colum} {agr_func} chart')    \n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "#bar_chat(test_truncated_data, 'year', 'year', 'count')\n",
    "\n",
    "def group_data(_data, grop_list_, agr_colum, agr_func):\n",
    "    grop_list=[grop_list_]\n",
    "    agg_func_math = {\n",
    "        agr_colum: [agr_func]\n",
    "    }\n",
    "    dict_data=_data.groupby(grop_list, group_keys=True, dropna=True).agg(agg_func_math).to_dict()[(agr_colum, agr_func)]\n",
    "    df=pd.DataFrame(list(dict_data. items ()), columns = [grop_list_, agr_colum])\n",
    "    #df.set_index(df[grop_list], *, drop=True, append=False, inplace=False, verify_integrity=False)[source]\n",
    "    df.set_index(grop_list, inplace=True)\n",
    "    return df.copy()\n",
    "\n",
    "def concat_data(train_data):\n",
    "    Trap=group_data(train_data, 'Trap', 'Latitude', 'min')\n",
    "    Longitude=group_data(train_data, 'Trap', 'Longitude', 'min')\n",
    "    NumMosquitos=group_data(train_data, 'Trap', 'NumMosquitos', 'sum')\n",
    "    WnvPresent=group_data(train_data, 'Trap', 'WnvPresent', 'sum')\n",
    "    AddressAccuracy=group_data(train_data, 'Trap', 'AddressAccuracy', 'min')\n",
    "    RESTUANS=group_data(train_data, 'Trap', 'RESTUANS', 'sum')\n",
    "    PIPIENS=group_data(train_data, 'Trap', 'PIPIENS', 'sum')\n",
    "    Date_Min=group_data(train_data, 'Trap', 'Date', 'min')\n",
    "    #Date_Max=group_data(train_data, 'Trap', 'Date', 'max')\n",
    "    \n",
    "    frames = [Trap, Longitude, Date_Min, NumMosquitos, WnvPresent, AddressAccuracy, RESTUANS, PIPIENS]\n",
    "    result = pd.concat(frames, axis=1)\n",
    "    result.reset_index(inplace=True)\n",
    "    return result.copy()\n",
    "#train_data\n",
    "#df=concat_data(train_data[(train_data['year']==2013)])\n",
    "#df['test']='2021'\n",
    "#df\n",
    "#weather_data\n",
    "def make_category(X_Data, list_category):\n",
    "    for i in list_category:\n",
    "        X_Data['Cat_category']=X_Data[i].astype(\"category\")\n",
    "        clear_data(X_Data, [i], revers=False)\n",
    "        print(i)\n",
    "        X_Data.rename(\n",
    "            columns={'Cat_category': i,  # колонка \"SibSp\" буде перейменована на \"SiblingsSpouses\"\n",
    "                    }, inplace=True  # покажчик того, що зміни вносяться до існуючої таблиці\n",
    "        )\n",
    "    return X_Data\n",
    "\n",
    "def clear_data(test_data, drop_list, revers):\n",
    "    columns_df=[column for column in test_data]\n",
    "    #print(columns_df)\n",
    "    if revers==False:\n",
    "        for i in drop_list:\n",
    "            if i in columns_df:\n",
    "                test_data.drop(\n",
    "                    i,  # список колонок або рядків, які потрібно видалити\n",
    "                    axis=1,  # видалення рядків відбувається аналогічно, щоб видалити саме колонки, вибираємо відповідну вісь\n",
    "                    inplace=True  # видалення \"на місці\", без надання нової змінної\n",
    "                )\n",
    "    \n",
    "        \n",
    "    if revers==True:\n",
    "        for i in columns_df:\n",
    "            if i in drop_list:\n",
    "                pass\n",
    "                #print(i)\n",
    "            else:\n",
    "                #print(i)\n",
    "                test_data.drop(\n",
    "                    i,  # список колонок або рядків, які потрібно видалити\n",
    "                    axis=1,  # видалення рядків відбувається аналогічно, щоб видалити саме колонки, вибираємо відповідну вісь\n",
    "                    inplace=True  # видалення \"на місці\", без надання нової змінної)\n",
    "                )\n",
    "                \n",
    "            \n",
    "    return test_data.copy()\n",
    "\n",
    "def replase_M_to_Max_int(weather_data, replase_column, date_type):\n",
    "    #df=weather_data.copy()\n",
    "    try:\n",
    "        weather_data[replase_column].unique()\n",
    "        weather_data[replase_column]=weather_data[replase_column].replace(regex=['M'], value='-1000').astype(str).astype(date_type)\n",
    "        \n",
    "        M=weather_data[replase_column].max()\n",
    "        \n",
    "        weather_data.loc[(weather_data[replase_column] ==-1000), replase_column] = M\n",
    "        print(f'{replase_column}_{M} {weather_data[replase_column].unique()}')\n",
    "    except Exception as _ex:\n",
    "        print(f\"[{replase_column}] Error\", _ex)\n",
    "    return weather_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeSum\n",
      "6.86\n",
      "Heat_29 [ 0 14 13  9  7 29  5  6  4 10  8 12  3  2  1 15 16 19 17 20 11 18 21 25\n",
      " 24 27 26 23 28 22]\n",
      "Cool_29 [ 2  3  0 29  5  4  6  8  7  9 10 13 11 12  1 15 16 17 14 20 19 18 21 22\n",
      " 24 27 23 26 28 25]\n",
      "Depart_23 [ 14  23  -3   2   4   5  10  12  13  -2  15  11  -4  -6   8  -5   1   9\n",
      "   6  -9  -8   3   0  -1  -7   7 -14  18  16  22  21  20 -10 -16  17 -12\n",
      " -11 -15 -17  19 -13]\n",
      "Tavg_94 [67 68 51 52 56 58 94 60 59 65 70 69 71 61 55 57 73 72 53 62 63 74 75 78\n",
      " 76 77 66 80 64 81 82 79 85 84 83 50 49 46 48 45 54 47 44 40 41 38 39 42\n",
      " 37 43 86 87 89 92 88 91 93 90 36]\n",
      "WetBulb_78 [56 57 47 48 50 49 46 54 53 62 63 60 61 51 59 58 43 44 45 65 66 67 64 52\n",
      " 55 69 68 70 72 71 73 74 76 42 39 40 41 35 33 34 78 75 36 32 38 77 37]\n",
      "StnPressure_29.86 [29.1  29.18 29.38 29.44 29.39 29.46 29.31 29.36 29.4  29.57 29.62 29.29\n",
      " 29.21 29.28 29.2  29.26 29.33 29.49 29.54 29.55 29.23 29.13 29.19 29.53\n",
      " 29.6  29.34 29.41 29.47 29.51 29.42 29.43 29.25 29.03 28.82 28.87 28.88\n",
      " 29.16 29.07 28.84 28.91 29.24 29.86 29.3  29.12 29.45 29.56 29.32 29.05\n",
      " 29.11 29.06 29.22 29.08 29.14 29.37 29.35 29.15 29.17 29.48 29.52 29.27\n",
      " 29.5  28.59 28.67 28.75 29.02 29.79 29.63 29.7  28.95 29.01 28.79 28.85\n",
      " 28.97 28.89 28.94 28.93 28.98 28.96 29.   29.66 29.09 28.9  29.04 29.59\n",
      " 29.65 29.58 29.61 29.64 29.71 29.67 28.8  28.73 29.68 28.74 28.55 28.63\n",
      " 28.92 28.99 28.81 28.71 28.69 28.77 28.83]\n",
      "AvgSpeed_26.3 [ 9.2  9.6 13.4 11.9 13.2 10.8 10.4 12.  11.5 15.  14.5 10.5  9.9  5.8\n",
      "  5.4  6.2  5.9  4.1  3.9 12.9 12.8 13.   8.1  7.6 17.3 14.6 12.3 12.2\n",
      " 11.8 11.3  7.5  5.5 11.4 10.7  9.7  8.2  7.8 10.2 10.6 11.2 15.2  8.8\n",
      "  7.2  9.5  5.3  5.2  6.5  7.4 10.1  6.4  6.7 23.1 20.7 13.8 12.4  5.\n",
      "  4.7  5.6  6.9  8.4 10.   8.6 26.3  6.8  4.9  6.1  6.3 15.1 12.6  7.7\n",
      "  8.7  9.   8.   6.   7.1  8.5 12.5 13.3  8.3  7.3 13.1 12.7 10.9 11.1\n",
      " 13.9  6.6 14.4  9.1  3.3  3.5  4.   7.   9.4  7.9  5.7  4.3  4.6  3.7\n",
      " 11.7  4.4 12.1 13.5 13.7 11.   9.8  8.9 10.3 15.5 18.9 17.2 16.7 18.\n",
      " 18.2 16.8 14.1 14.7  4.2  9.3 14.3 17.7 17.8 15.9 19.3 17.4  3.8  4.8\n",
      " 14.  21.5 19.5 16.3  5.1  3.6  3.2  4.5  2.9  3.1  2.7 18.4 16.4 14.8\n",
      " 11.6 13.6  2.4  2.6  3.4  3.   2.1 20.2 14.9 16.2 15.4 17.9 14.2 15.3\n",
      " 15.7 16.1 18.8 17.1 16.6 21.4 23.2 22.1 15.6 16.9  2.   2.3  1.7 19.9\n",
      " 17.6 18.5 18.1 16.  15.8  2.8  1.9 22.9 22.6]\n",
      "SeaLevel_30.53 [29.82 30.09 30.08 30.12 30.05 30.04 30.1  30.29 30.28 30.03 30.02 29.94\n",
      " 29.93 29.92 29.91 30.2  30.19 30.24 29.97 29.98 29.84 29.83 30.27 30.25\n",
      " 30.26 30.11 30.06 30.23 30.15 30.14 30.   29.99 29.9  29.77 29.76 29.56\n",
      " 29.54 29.52 29.51 29.79 29.78 29.81 29.55 29.85 30.07 30.16 30.53 29.96\n",
      " 29.95 30.13 30.21 30.22 29.88 30.01 29.8  29.89 29.74 29.87 29.86 30.18\n",
      " 30.17 29.34 29.44 29.45 29.71 29.72 30.52 30.4  30.41 29.67 29.53 29.69\n",
      " 29.61 29.64 29.63 29.66 29.7  30.34 30.33 29.62 29.6  29.75 29.68 29.73\n",
      " 30.31 30.3  30.32 30.37 30.39 29.59 29.65 30.35 30.36 29.48 30.38 29.5\n",
      " 29.25 29.23 29.46 29.43 29.47]\n"
     ]
    }
   ],
   "source": [
    "#weather_data\n",
    "\n",
    "weather_data=clear_data(weather_data, ['Water1'], revers=False)\n",
    "list_category=['CodeSum']\n",
    "weather_data=make_category (weather_data, list_category)    \n",
    "\n",
    "#Depth_2\n",
    "replase_column='Depth'\n",
    "weather_data[replase_column].unique()\n",
    "level_map = {'0': 0, 'M': 1}\n",
    "weather_data[replase_column] = weather_data[replase_column].map(level_map).astype(str).astype(int)\n",
    "#weather_data[replase_column].unique()\n",
    "\n",
    "\n",
    "#SnowFall\n",
    "replase_column='SnowFall'\n",
    "level_map = {'0.0': 0, 'M': 0.5, '  T':1,  '0.1':0.1}\n",
    "weather_data[replase_column] = weather_data[replase_column].map(level_map).astype(str).astype(float)\n",
    "weather_data[replase_column].unique()\n",
    "\n",
    "#Sunrise\n",
    "replase_column='Sunrise'\n",
    "weather_data[replase_column] =weather_data[replase_column] .replace(regex=['-'],value='0').astype(str).astype(int)\n",
    "#weather_data[replase_column].unique()\n",
    "\n",
    "#Sunset\n",
    "replase_column='Sunset'\n",
    "weather_data[replase_column] =weather_data[replase_column] .replace(regex=['-'],value='0').astype(str).astype(int)\n",
    "#weather_data[replase_column].unique()\n",
    "\n",
    "#PrecipTotal\n",
    "replase_column='PrecipTotal'\n",
    "weather_data[replase_column] =weather_data[replase_column] .replace(regex=['M'],value='-1000')\n",
    "M=weather_data[replase_column].max()\n",
    "weather_data.loc[(weather_data[replase_column] =='-1000'), replase_column] = M\n",
    "print (M)\n",
    "\n",
    "\n",
    "\n",
    "weather_data[replase_column] =weather_data[replase_column] .replace(regex=['  T'],value='0')\n",
    "'''T=weather_data[replase_column].min()\n",
    "print (f'{T}_{weather_data.loc[(weather_data[replase_column] ==1000), replase_column]}')\n",
    "weather_data.loc[(weather_data[replase_column] ==1000), replase_column] = weather_data[replase_column].min()'''\n",
    "weather_data['1']=weather_data[replase_column].astype(str).astype(float)\n",
    "\n",
    "\n",
    "clear_data(weather_data, [replase_column], revers=False)\n",
    "\n",
    "weather_data.rename(\n",
    "            columns={'1': replase_column,  # колонка \"SibSp\" буде перейменована на \"SiblingsSpouses\"\n",
    "                    }, inplace=True  # покажчик того, що зміни вносяться до існуючої таблиці\n",
    "        )\n",
    "\n",
    "#weather_data[replase_column].unique()\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'Heat', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'Cool', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'Depart', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'Tavg', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'WetBulb', int)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'StnPressure', float)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'AvgSpeed', float)\n",
    "weather_data=replase_M_to_Max_int(weather_data, 'SeaLevel', float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for col in weather_data:\\n    print(f'{col}_{weather_data[col].unique()}')\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for col in weather_data:\n",
    "    print(f'{col}_{weather_data[col].unique()}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Trap</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Date</th>\n",
       "      <th>NumMosquitos</th>\n",
       "      <th>WnvPresent</th>\n",
       "      <th>AddressAccuracy</th>\n",
       "      <th>RESTUANS</th>\n",
       "      <th>PIPIENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>T002</td>\n",
       "      <td>41.954690</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>2009-08-07</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>T003</td>\n",
       "      <td>41.964242</td>\n",
       "      <td>-87.757639</td>\n",
       "      <td>2009-08-07</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>T008</td>\n",
       "      <td>42.008314</td>\n",
       "      <td>-87.777921</td>\n",
       "      <td>2009-08-07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>T009</td>\n",
       "      <td>41.992478</td>\n",
       "      <td>-87.862995</td>\n",
       "      <td>2009-08-07</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>T011</td>\n",
       "      <td>41.944869</td>\n",
       "      <td>-87.832763</td>\n",
       "      <td>2009-08-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>46</td>\n",
       "      <td>T152</td>\n",
       "      <td>41.846075</td>\n",
       "      <td>-87.716277</td>\n",
       "      <td>2007-07-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>47</td>\n",
       "      <td>T155</td>\n",
       "      <td>41.776156</td>\n",
       "      <td>-87.778927</td>\n",
       "      <td>2007-07-27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>48</td>\n",
       "      <td>T218</td>\n",
       "      <td>41.948167</td>\n",
       "      <td>-87.730698</td>\n",
       "      <td>2007-07-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>49</td>\n",
       "      <td>T219</td>\n",
       "      <td>41.966987</td>\n",
       "      <td>-87.674677</td>\n",
       "      <td>2007-07-27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>50</td>\n",
       "      <td>T220</td>\n",
       "      <td>41.963976</td>\n",
       "      <td>-87.691810</td>\n",
       "      <td>2007-07-27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3427 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Trap   Latitude  Longitude        Date  NumMosquitos  WnvPresent  \\\n",
       "0         0  T002  41.954690 -87.800991  2009-08-07            13           0   \n",
       "1         1  T003  41.964242 -87.757639  2009-08-07             6           0   \n",
       "2         2  T008  42.008314 -87.777921  2009-08-07             2           0   \n",
       "3         3  T009  41.992478 -87.862995  2009-08-07             6           0   \n",
       "4         4  T011  41.944869 -87.832763  2009-08-07             5           0   \n",
       "...     ...   ...        ...        ...         ...           ...         ...   \n",
       "3422     46  T152  41.846075 -87.716277  2007-07-27             1           0   \n",
       "3423     47  T155  41.776156 -87.778927  2007-07-27             2           0   \n",
       "3424     48  T218  41.948167 -87.730698  2007-07-27             1           0   \n",
       "3425     49  T219  41.966987 -87.674677  2007-07-27             2           0   \n",
       "3426     50  T220  41.963976 -87.691810  2007-07-27             2           0   \n",
       "\n",
       "      AddressAccuracy  RESTUANS  PIPIENS  \n",
       "0                   9         2        2  \n",
       "1                   8         2        2  \n",
       "2                   9         1        1  \n",
       "3                   8         2        2  \n",
       "4                   8         2        2  \n",
       "...               ...       ...      ...  \n",
       "3422                9         1        1  \n",
       "3423                9         1        1  \n",
       "3424                8         1        1  \n",
       "3425                8         2        2  \n",
       "3426                9         2        2  \n",
       "\n",
       "[3427 rows x 10 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "train_data=add_datetime(train_data)\n",
    "train_data['RESTUANS']=train_data['Species'].str.contains('True').astype(str).astype(bool)\n",
    "train_data['PIPIENS']=train_data['Species'].str.contains('True').astype(str).astype(bool)\n",
    "\n",
    "test_truncated_data=add_datetime(test_truncated_data)\n",
    "weather_data=add_datetime(weather_data)\n",
    "\n",
    "def iter_days(draft_year, draft_month):\n",
    "    dt = datetime(draft_year, draft_month, 1)\n",
    "    while dt.year == draft_year and  dt.month == draft_month:\n",
    "        yield dt\n",
    "        dt += timedelta(days=1)\n",
    "        \n",
    "#draft_year_list={2007, 2009, 2013}\n",
    "#draft_month_list={6, 7, 8, 9}\n",
    "draft_year_list={2007, 2009, 2013}\n",
    "draft_month_list={6, 7, 8, 9}\n",
    "frames=[]\n",
    "for draft_year in draft_year_list:\n",
    "    data_year=train_data[train_data['year']==draft_year].copy()\n",
    "    #print(draft_year)\n",
    "    for draft_month in draft_month_list:\n",
    "        #print(draft_month)\n",
    "        train_data_month=data_year[(data_year['month']==draft_month)]\n",
    "        for dt in iter_days(draft_year, draft_month):\n",
    "            train_data_day=concat_data(train_data_month[(train_data_month['day']==dt.day)])\n",
    "            if train_data_day.shape[0]>0:\n",
    "                train_data_day.set_index('Date', inplace=False)\n",
    "                frames.append(train_data_day)\n",
    "\n",
    "result = pd.concat(frames, axis=0)\n",
    "result.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge weather_data and test_data\n",
    "\n",
    "weather_1=weather_data[weather_data['Station']==1].copy()\n",
    "weather_1.set_index('Date', inplace=True)\n",
    "weather_2=weather_data[weather_data['Station']==2].copy()\n",
    "weather_2.set_index('Date', inplace=True)\n",
    "\n",
    "weather=weather_1.merge(weather_2,\n",
    "    #weather_1, left_on='Date', right_on='Date')\n",
    "    how='inner',\n",
    "    #on=None, \n",
    "    left_on='Date', right_on='Date', \n",
    "    #left_index=True, right_index=True,\n",
    "    #, sort=False,\n",
    "    suffixes=('_1', '_2'), copy=True\n",
    "    #, indicator=False, validate=None\n",
    ")\n",
    "test_data=result.merge(weather,\n",
    "    #weather_1, left_on='Date', right_on='Date')\n",
    "    how='inner',\n",
    "    #on=None, \n",
    "    left_on='Date', right_on='Date', \n",
    "    #left_index=True, right_index=True,\n",
    "    #, sort=False,\n",
    "    #suffixes=('_x', '_y'), copy=True\n",
    "    #, indicator=False, validate=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 'CodeSum_1'\n",
      "Error 'CodeSum_2'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3427 entries, 0 to 3426\n",
      "Data columns (total 51 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Trap             3427 non-null   object \n",
      " 1   Latitude         3427 non-null   float64\n",
      " 2   Longitude        3427 non-null   float64\n",
      " 3   Date             3427 non-null   object \n",
      " 4   NumMosquitos     3427 non-null   int64  \n",
      " 5   WnvPresent       3427 non-null   int64  \n",
      " 6   AddressAccuracy  3427 non-null   int64  \n",
      " 7   RESTUANS         3427 non-null   int64  \n",
      " 8   PIPIENS          3427 non-null   int64  \n",
      " 9   Station_1        3427 non-null   int64  \n",
      " 10  Tmax_1           3427 non-null   int64  \n",
      " 11  Tmin_1           3427 non-null   int64  \n",
      " 12  Tavg_1           3427 non-null   int32  \n",
      " 13  Depart_1         3427 non-null   int32  \n",
      " 14  DewPoint_1       3427 non-null   int64  \n",
      " 15  WetBulb_1        3427 non-null   int32  \n",
      " 16  Heat_1           3427 non-null   int32  \n",
      " 17  Cool_1           3427 non-null   int32  \n",
      " 18  Sunrise_1        3427 non-null   int32  \n",
      " 19  Sunset_1         3427 non-null   int32  \n",
      " 20  Depth_1          3427 non-null   int32  \n",
      " 21  SnowFall_1       3427 non-null   float64\n",
      " 22  StnPressure_1    3427 non-null   float64\n",
      " 23  SeaLevel_1       3427 non-null   float64\n",
      " 24  ResultSpeed_1    3427 non-null   float64\n",
      " 25  ResultDir_1      3427 non-null   int64  \n",
      " 26  AvgSpeed_1       3427 non-null   float64\n",
      " 27  PrecipTotal_1    3427 non-null   float64\n",
      " 28  day_1            3427 non-null   int64  \n",
      " 29  weekday_1        3427 non-null   int64  \n",
      " 30  month_1          3427 non-null   int64  \n",
      " 31  year_1           3427 non-null   int64  \n",
      " 32  Station_2        3427 non-null   int64  \n",
      " 33  Tmax_2           3427 non-null   int64  \n",
      " 34  Tmin_2           3427 non-null   int64  \n",
      " 35  Tavg_2           3427 non-null   int32  \n",
      " 36  Depart_2         3427 non-null   int32  \n",
      " 37  DewPoint_2       3427 non-null   int64  \n",
      " 38  WetBulb_2        3427 non-null   int32  \n",
      " 39  Heat_2           3427 non-null   int32  \n",
      " 40  Cool_2           3427 non-null   int32  \n",
      " 41  Sunrise_2        3427 non-null   int32  \n",
      " 42  Sunset_2         3427 non-null   int32  \n",
      " 43  Depth_2          3427 non-null   int32  \n",
      " 44  SnowFall_2       3427 non-null   float64\n",
      " 45  StnPressure_2    3427 non-null   float64\n",
      " 46  SeaLevel_2       3427 non-null   float64\n",
      " 47  ResultSpeed_2    3427 non-null   float64\n",
      " 48  ResultDir_2      3427 non-null   int64  \n",
      " 49  AvgSpeed_2       3427 non-null   float64\n",
      " 50  PrecipTotal_2    3427 non-null   float64\n",
      "dtypes: float64(14), int32(16), int64(19), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#test_data clear\n",
    "def clear_dtype(weather_data, drop_dtype_list):\n",
    "    for col in weather_data:\n",
    "        if str(weather_data[col].dtypes) in drop_dtype_list:\n",
    "            try:\n",
    "                weather_data.drop(\n",
    "                    weather_data[col].name,  # список колонок або рядків, які потрібно видалити\n",
    "                    axis=1,  # видалення рядків відбувається аналогічно, щоб видалити саме колонки, вибираємо відповідну вісь\n",
    "                    inplace=True  # видалення \"на місці\", без надання нової змінної\n",
    "                )\n",
    "                #X_Data=clear_data(X_Data, X_Data[col].name, revers=False)\n",
    "                print(f'{col}_{weather_data[col].name}_{weather_data[col].dtypes}')\n",
    "                return weather_data.copy()\n",
    "            except Exception as _ex:\n",
    "                print(f\"Error\", _ex)\n",
    "                \n",
    "                \n",
    "drop_list=['year_2', 'month_2', 'weekday_2', 'day_2']\n",
    "test_data=clear_data(test_data, drop_list, revers=False)\n",
    "\n",
    "#drop_dtype_list=['bool', 'category', 'int64' ,'int32', 'float64', ]\n",
    "drop_dtype_list=['category']                \n",
    "clear_dtype(test_data, drop_dtype_list)\n",
    "\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_drop_list=['NumMosquitos', 'WnvPresent', 'RESTUANS', 'PIPIENS', 'Trap', 'Date', 'Latitude', 'Longitude']\n",
    "\n",
    "X_drop_list=['NumMosquitos', 'WnvPresent', 'Trap', 'Date']\n",
    "X_Data=clear_data(test_data.copy(), X_drop_list, revers=False)\n",
    "\n",
    "Y_Data=clear_data(test_data.copy(), X_drop_list, revers=True)\n",
    "Y_Data=clear_data(Y_Data, ['Trap', 'Date'], revers=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3427 entries, 0 to 3426\n",
      "Data columns (total 47 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Latitude         3427 non-null   float64\n",
      " 1   Longitude        3427 non-null   float64\n",
      " 2   AddressAccuracy  3427 non-null   int64  \n",
      " 3   RESTUANS         3427 non-null   int64  \n",
      " 4   PIPIENS          3427 non-null   int64  \n",
      " 5   Station_1        3427 non-null   int64  \n",
      " 6   Tmax_1           3427 non-null   int64  \n",
      " 7   Tmin_1           3427 non-null   int64  \n",
      " 8   Tavg_1           3427 non-null   int32  \n",
      " 9   Depart_1         3427 non-null   int32  \n",
      " 10  DewPoint_1       3427 non-null   int64  \n",
      " 11  WetBulb_1        3427 non-null   int32  \n",
      " 12  Heat_1           3427 non-null   int32  \n",
      " 13  Cool_1           3427 non-null   int32  \n",
      " 14  Sunrise_1        3427 non-null   int32  \n",
      " 15  Sunset_1         3427 non-null   int32  \n",
      " 16  Depth_1          3427 non-null   int32  \n",
      " 17  SnowFall_1       3427 non-null   float64\n",
      " 18  StnPressure_1    3427 non-null   float64\n",
      " 19  SeaLevel_1       3427 non-null   float64\n",
      " 20  ResultSpeed_1    3427 non-null   float64\n",
      " 21  ResultDir_1      3427 non-null   int64  \n",
      " 22  AvgSpeed_1       3427 non-null   float64\n",
      " 23  PrecipTotal_1    3427 non-null   float64\n",
      " 24  day_1            3427 non-null   int64  \n",
      " 25  weekday_1        3427 non-null   int64  \n",
      " 26  month_1          3427 non-null   int64  \n",
      " 27  year_1           3427 non-null   int64  \n",
      " 28  Station_2        3427 non-null   int64  \n",
      " 29  Tmax_2           3427 non-null   int64  \n",
      " 30  Tmin_2           3427 non-null   int64  \n",
      " 31  Tavg_2           3427 non-null   int32  \n",
      " 32  Depart_2         3427 non-null   int32  \n",
      " 33  DewPoint_2       3427 non-null   int64  \n",
      " 34  WetBulb_2        3427 non-null   int32  \n",
      " 35  Heat_2           3427 non-null   int32  \n",
      " 36  Cool_2           3427 non-null   int32  \n",
      " 37  Sunrise_2        3427 non-null   int32  \n",
      " 38  Sunset_2         3427 non-null   int32  \n",
      " 39  Depth_2          3427 non-null   int32  \n",
      " 40  SnowFall_2       3427 non-null   float64\n",
      " 41  StnPressure_2    3427 non-null   float64\n",
      " 42  SeaLevel_2       3427 non-null   float64\n",
      " 43  ResultSpeed_2    3427 non-null   float64\n",
      " 44  ResultDir_2      3427 non-null   int64  \n",
      " 45  AvgSpeed_2       3427 non-null   float64\n",
      " 46  PrecipTotal_2    3427 non-null   float64\n",
      "dtypes: float64(14), int32(16), int64(17)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3427 entries, 0 to 3426\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   NumMosquitos  3427 non-null   int64\n",
      " 1   WnvPresent    3427 non-null   int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 80.3 KB\n"
     ]
    }
   ],
   "source": [
    "Y_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Помилка на навчальному наборі:  1077.7509912727264\n",
      "Помилка на тестовому наборі:  967.1932847979036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_Data,  # перший масив, який потрібно розділити\n",
    "    Y_Data,  # другий масив, який потрібно роздолити\n",
    "    test_size=0.2,  # розмір меншої групи (20% від загальної кількості даних)\n",
    "    random_state=42  # фіксація випадкового стану: тепер при перезапуску групи будуть однаковими\n",
    ")\n",
    "\n",
    "    # формальність для того, щоб не бачити попередження про зміни на зрізі з таблиці\n",
    "X_train, X_test = X_train.copy(), X_test.copy()\n",
    "    # побудуємо модель\n",
    "mdl = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # оцінимо точність моделі\n",
    "train_predictions = mdl.predict(X_train)\n",
    "test_predictions = mdl.predict(X_test)\n",
    "\n",
    "print('Помилка на навчальному наборі: ', mean_squared_error(y_train, train_predictions))\n",
    "print('Помилка на тестовому наборі: ', mean_squared_error(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centr_map():\n",
    "    map_ = folium.Map(location=[train_data['Latitude'].mean(),  train_data['Longitude'].mean()],\n",
    "               tiles=\"Stamen Terrain\", zoom_start=10, control_scale=False)\n",
    "\n",
    "    Station=folium.FeatureGroup(name='Station')\n",
    "    Station.add_to(map_)\n",
    "    Station.add_child(\n",
    "        folium.Marker([41.995,  -87.933],\n",
    "                      popup=\"CHICAGO O'HARE INTERNATIONAL AIRPORT\").add_to(map_))\n",
    "    Station.add_child(\n",
    "        folium.Marker(\n",
    "            [41.786,  -88.089163], popup=\"CHICAGO MIDWAY INTL ARPT\").add_to(map_))\n",
    "    return map_ \n",
    "\n",
    "map_=centr_map()\n",
    "\n",
    "\n",
    "\n",
    "df=spray_data\n",
    "time_index = list(spray_data['Date'].sort_values().astype('str').unique())\n",
    "\n",
    "\n",
    "df['Date'] = df['Date'].sort_values(ascending=True)\n",
    "data = []\n",
    "\n",
    "for _, d in df.groupby('Date'):\n",
    "    #print(f'{row}')\n",
    "    data.append([[row['Latitude'], row['Longitude'], 1] for _, row in d.iterrows()])\n",
    "\n",
    "hm = plugins.HeatMapWithTime(\n",
    "    data,\n",
    "    name=\"Spray\",\n",
    "    index=time_index,\n",
    "    auto_play=True,\n",
    "    min_opacity=0,\n",
    "    max_opacity=0.7,\n",
    "    #gradient={0.1:'blue', 0.25:'green', 0.5:'yelow', 0.75:'orange', 1:'red'} \n",
    ")\n",
    "hm.add_to(map_)\n",
    "\n",
    "folium.LayerControl().add_to(map_)\n",
    "map_.save(f\"sklearn_linear_model.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_=centr_map()\n",
    "\n",
    "\n",
    "\n",
    "df=test_data.copy()\n",
    "time_index = list(test_data['Date'].sort_values().astype('str').unique())\n",
    "\n",
    "\n",
    "df['Date'] = df['Date'].sort_values(ascending=True)\n",
    "data = []\n",
    "\n",
    "for _, d in df.groupby('Date'):\n",
    "    #print(f'{row}')\n",
    "    data.append([[row['Latitude'], row['Longitude'], 1] for _, row in d.iterrows()])\n",
    "\n",
    "test_data_hm = plugins.HeatMapWithTime(\n",
    "    data,\n",
    "    name=\"test_data\",\n",
    "    index=time_index,\n",
    "    auto_play=True,\n",
    "    min_opacity=0,\n",
    "    max_opacity=0.7,\n",
    "    #gradient={0.1:'blue', 0.25:'green', 0.5:'yelow', 0.75:'orange', 1:'red'} \n",
    ")\n",
    "test_data_hm.add_to(map_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(map_)\n",
    "map_.save(f\"test_data.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_markers(): \n",
    "    # train_data_point_map\n",
    "    draft_year_list={2007, 2009, 2013}\n",
    "    draft_month_list={6, 7, 8, 9}\n",
    "    geometry = geopandas.points_from_xy(train_data.Longitude, train_data.Latitude)\n",
    "    geo_df = geopandas.GeoDataFrame(\n",
    "        train_data, geometry=geometry\n",
    "    )\n",
    "    geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in geo_df.geometry]\n",
    "\n",
    "    wnvpresentsLayer=folium.FeatureGroup(name='wnvpresents')\n",
    "    wnvpresentsLayer.add_to(map_)\n",
    "\n",
    "    # Iterate through list and add a marker for each volcano, color-coded by its type.\n",
    "    i = 0\n",
    "    for coordinates in geo_df_list:\n",
    "        if (geo_df.month[i] == draft_month) and  (geo_df.year[i] == draft_year):\n",
    "            wnvpresents=int(train_data[(geo_df['Trap'] == geo_df.Trap[i]) & (geo_df['month']==draft_month) \n",
    "                       & (geo_df['year']==draft_year)]['WnvPresent'].sum())\n",
    "            if wnvpresents>0:\n",
    "                if geo_df.PIPIENS[i] == True:\n",
    "                    type_color = \"green\"\n",
    "                if (geo_df.RESTUANS[i] == True):\n",
    "                    type_color = \"red\"\n",
    "                    # Place the markers with the popup labels and data\n",
    "                wnvpresentsLayer.add_child(\n",
    "                    folium.Marker(\n",
    "                        location=coordinates,\n",
    "                        popup=geo_df.Trap[i]+ \"<br>\"\n",
    "                        +'wnvpresents '+ str(wnvpresents)+ \"<br>\"+'numMosquitos '+ str(numMosquitos(draft_year, draft_month)),\n",
    "                        icon=folium.Icon(color=\"%s\" % type_color)\n",
    "                        )\n",
    "                )\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datasetes():\n",
    "    fig = plt.figure()\n",
    "\n",
    "    plot_mas = test_truncated_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='blue', label='test_truncated_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True) \n",
    "\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plot_mas = weather_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='pink', label='weather_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    #fig2 = plt.figure()\n",
    "\n",
    "    plot_mas = train_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='green', label='train_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plot_mas = spray_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='red', label='spray_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plot_mas = test_truncated_data.groupby(['year'], group_keys=True,\n",
    "                                           dropna=True).agg({'year': ['count']}).to_dict()[('year', 'count')] \n",
    "    plt.bar(plot_mas.keys(), plot_mas.values(), color='red', label='test_truncated_data counts  in year')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   # лінії допоміжної сітки\n",
    "\n",
    "plot_datasetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chat(_data, grop_list_, agr_colum, agr_func):\n",
    "    grop_list=[grop_list_]\n",
    "    agg_func_math = {\n",
    "        agr_colum: [agr_func]\n",
    "    }\n",
    "\n",
    "    plot_mas = _data.groupby(grop_list, group_keys=True, dropna=True).agg(agg_func_math).to_dict()[(agr_colum, agr_func)] \n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.bar(plot_mas.keys(), plot_mas.values())\n",
    "    plt.title(f'{grop_list_} {agr_colum} {agr_func} chart')\n",
    "    \n",
    "    plt.grid(True)   # лінії допоміжної сітки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_mas = train_data.groupby(['month'], group_keys=True,\n",
    "                              dropna=True).agg({'WnvPresent': ['sum']}).to_dict()[('WnvPresent', 'sum')] \n",
    "plt.bar(plot_mas.keys(), plot_mas.values(), color='red', label='WnvPresent sum month')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(False)   # лінії допоміжної сітки\n",
    "#Date\n",
    "fig = plt.figure()\n",
    "plot_mas = train_data.groupby(['Date'], group_keys=True,\n",
    "                              dropna=True).agg({'WnvPresent': ['sum']}).to_dict()[('WnvPresent', 'sum')] \n",
    "plt.bar(plot_mas.keys(), plot_mas.values(), color='red', label='WnvPresent sum Date')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(False)   # лінії допоміжної сітки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_adres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our key point when map open it\n",
    "map_ = folium.Map(location=[train_data_adres['Latitude'].mean(),  train_data_adres['Longitude'].mean()],\n",
    "               tiles=\"Stamen Terrain\", zoom_start=10, control_scale=False)\n",
    "\n",
    "for la,lo in train_data_adres:\n",
    "    folium.Marker(\n",
    "        location=[la,lo],\n",
    "        icon=folium.Icon(icon_color='white')\n",
    "    ).add_to(map2)\n",
    "# Plotting \n",
    "map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = folium.Map(location=[train_data_adres['Latitude'].mean(),  train_data_adres['Longitude'].mean()],\n",
    "               tiles=\"Stamen Terrain\", zoom_start=10, control_scale=False)\n",
    "\n",
    "folium.Marker(train_data_adres['Latitude','Longitude'], popup=train_data_adres['Trap']).add_to(map_)\n",
    "map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import folium\n",
    "#Station_1: CHICAGO O'HARE INTERNATIONAL AIRPORT Lat: 41.995 Lon: -87.933 Elev: 662 ft. above sea level\n",
    "#Station_2: CHICAGO MIDWAY INTL ARPT Lat: 41.786 Lon: -87.752 Elev: 612 ft. above sea level\n",
    "\n",
    "#m = folium.Map(location=[45.5236, -122.6750])\n",
    "#m = folium.Map(location=[42.391623, -88.089163], tiles=\"Stamen Terrain\", zoom_start=13)\n",
    "\n",
    "\n",
    "map_ = folium.Map(location=[spray_data['Latitude'].mean(),  spray_data['Longitude'].mean()],\n",
    "               tiles=\"Stamen Terrain\", zoom_start=10, control_scale=False)\n",
    "\n",
    "folium.Marker([41.995,  -87.933], popup=\"CHICAGO O'HARE INTERNATIONAL AIRPORT\").add_to(map_)\n",
    "folium.Marker([41.786,  -88.089163], popup=\"CHICAGO MIDWAY INTL ARPT\").add_to(map_)\n",
    "\n",
    "folium.CircleMarker(\n",
    "    location=[spray_data['Latitude'].mean(),  spray_data['Longitude'].mean()],\n",
    "    radius=10,\n",
    "    popup=\"spray_mean\",\n",
    "    color=\"#3186cc\",\n",
    "    fill=True,\n",
    "    fill_color=\"#3186cc\",\n",
    ").add_to(map_)\n",
    "\n",
    "\n",
    "#train_data_adres\n",
    "#for index, location_info in train_data.iterrows():\n",
    "#    folium.Marker([location_info[\"Latitude\"], location_info[\"Longitude\"]], popup=location_info[\"NumMosquitos\"]).add_to(map_)\n",
    "\n",
    "map_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
